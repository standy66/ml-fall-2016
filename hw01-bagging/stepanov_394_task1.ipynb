{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "МФТИ ФИВТ: Курс Машинное Обучение (осень, 2016), Арсений Ашуха, ars.ashuha@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Organization Info</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Дополнительный материал для выполнения дз**:\n",
    "- Hastie, The Elements of Statistical Learning, https://goo.gl/k3wfEU\n",
    "    - 2.9 Model Selection and the Bias–Variance Tradeoff \n",
    "    - 15 Random Forests\n",
    "- Соколов, Семинары по композиционным методам, https://goo.gl/sn8RyJ\n",
    "- Andrew Ng, Bias vs. Variance, https://goo.gl/1ISZ6Y\n",
    "\n",
    "**Оформление дз**: \n",
    "- Присылайте выполненное задание на почту ``ml.course.mipt@gmail.com``\n",
    "- Укажите тему письма в следующем формате ``ML2016_fall <номер_группы> <фамилия>``, к примеру -- ``ML2016_fall 401 ivanov``\n",
    "- Выполненное дз сохраните в файл ``<фамилия>_<группа>_task<номер>.ipnb``, к примеру -- ``ivanov_401_task1.ipnb``\n",
    "\n",
    "**Вопросы**:\n",
    "- Присылайте вопросы на почту ``ml.course.mipt@gmail.com``\n",
    "- Укажите тему письма в следующем формате ``ML2016_fall Question <Содержание вопроса>``\n",
    "\n",
    "--------\n",
    "- **PS1**: Мы используем автоматические фильтры, и просто не найдем ваше дз, если вы не аккуратно его подпишите.\n",
    "- **PS2**: Напоминаем, что дедлайны жесткие, письма пришедшие после автоматически удаляются =( чтобы соблазна не было "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Check Questions</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ответе на вопросы своими словами (загугленный материал надо пересказать), ответ обоснуйте (напишите и ОБЪЯСНИТЕ формулки если потребуется), если не выходит, то вернитесь к лекции дополнительным материалам:\n",
    "\n",
    "**Вопрос 1**: Какие формулы у шума, смещения, разброса? Какой смысл у этих компонент?\n",
    "\n",
    "Пусть $y^*(x) = \\mathbb{E}[y | x]$ -- оптимальный алгоритм, $\\mu$ -- метод обучения, $\\overline{y}(x) = \\mathbb{E}_{X^l}[\\mu\\{X^l\\}(x)]$ -- ответ, получаемый на $x$, при обучении усредненного алгоритма. Тогда\n",
    "$$Noise = \\mathbb{E}_{x, y}[(y - y^{*}(x))^2]$$\n",
    "Шум в данных, вызванный случайной природой выборки\n",
    "$$Bias = \\mathbb{E}_{x, y}[(\\overline{y}(x) - y^*(x))^2]$$\n",
    "Квадрат смещения среднего алгоритма от оптимального\n",
    "$$Variance = \\mathbb{E}_{X^l, x, y}[(\\mu\\{X^l\\}(x) - \\overline{y}(x))^2]$$\n",
    "Разброс семейства алгоритмов.\n",
    "\n",
    "**Вопрос 2**: 4. Приведите пример семейства с маленьким смещением и большим разбросом. Приведите пример семейства с большим смещением и маленьким разбросом.\n",
    "\n",
    "Decision tree имеет маленькое смещение, но большой разброс, так как при небольшом изменении данных дерево сильно изменится, и сложность разделяющей поверхности ничем не ограничена.\n",
    "\n",
    "Линейные алгоритмы имеют большое смещение и маленький разброс, так как при небольшом изменении данных, гиперповерхность, разделяющая данные, повернется не сильно и линейные алгоритмы способны восстанавливать только линейные зависимости (если не добавлять признаки высших порядков).\n",
    "\n",
    "**Вопрос 3**: Как сгенерировать подвыборку с помощью бутстрапа?\n",
    "\n",
    "Равномерный сэмплинг их исходной выборки с повторениями\n",
    "\n",
    "**Вопрос 4**: Что такое бэггинг?\n",
    "\n",
    "Усреднение ответов базовых алгоритмов, обученных на разных подвыборках, полученных бустрапом.\n",
    "\n",
    "**Вопрос 5**:  Как соотносятся смещение разброс композиции, построенной с помощью бэггинга, со смещением и разбросом одного базового алгоритма?\n",
    "\n",
    "Смещение одинаковое, а разброс падает с увеличением колиечтсва деревьев и уменьшением корреляции между ними. \n",
    "\n",
    "**Вопрос 6**: Как обучается случайный лес? В чем отличия от обычной процедуры построения решающих деревьев?\n",
    "\n",
    "Выбирается случайная подвыборка для обучения каждого дерева и иногда случайный набор признаков. В некоторых вариантах построения набор признаков изменяется от дерева к дереву, в других вариантах он изменяется от вершины к вершине одного и того же дерева.\n",
    "\n",
    "**Вопрос 7**: Почему хорошими базовыми алгоритмами для бэггинга являются именно деревья?\n",
    "\n",
    "Деревья имеют небольшое смещение, а их разброс падает с увеличением количества деревьев в лесе и уменьшением корреляций между ответами деревьев.\n",
    "\n",
    "**Вопрос 8**: Как оценить качество случайного леса с помощью out-of-bag-процедуры?\n",
    "\n",
    "Для каждого x ошибка считается и усредняется только на деревьях, которые не обучались на x, далее ошибка усредняется по всем x.\n",
    "\n",
    "-----------\n",
    "PS: Если проверяющий не понял ответ на большинство вопросов, то будет пичалька. Пишите так, чтобы можно было разобраться. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1 align=\"center\">Bagging</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Известно, что бэггинг плохо работает, если в качестве базовых классификаторов взять knn. Попробуем понять причины на простом примере.\n",
    "\n",
    "Пусть дана выборка $X^l$ из $l$ объектов с ответами из множества $Y = \\{−1, +1\\}$. Будем рассматривать классификатор одного ближайшего соседа в качестве базового алгоритма. Построим с помощью бэггинга композицию длины $N$:\n",
    "\n",
    "$$a_N(x) = sign(\\sum_{n=1}^{N} b_n(x))$$\n",
    "\n",
    "Оцените вероятность того, что ответ композиции на произвольном объекте x будет\n",
    "отличаться от ответа одного классификатора ближайшего соседа, обученного по всей\n",
    "выборке. Покажите, что эта вероятность стремится к нулю при N → ∞."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "Пусть $X_1^l, \\dots, X_N^l$ -- случайные независимые выборки с повторением размера $l$ из $X^l$, на которых были обучены алгоритмы $b_1, \\dots, b_N$.\n",
    "\n",
    "Без ограничения общности пусть ответ 1NN обученного на всей выборке +1, а ответ композиции -1. Это значит, что ближайшая к $x$ точка из $X^l$ (пусть это будет точка $x_0$) имеет метку +1, а среди ответов базовых алгоритмов в композиции преобладает -1. В частности это означает, что хотя бы на половине из $X_1^l, \\dots, X_N^l$ ближайшая к $x$ точка имеет метку -1. В частности это означает, что $x_0$ не попала хотя бы в половину из $X_1^l, \\dots, X_N^l$. А вероятность такого события -- $(1 - 1/l)^{Nl/2} \\rightarrow 0$. Кстати, последняя вероятность асимптотически равна $e^{-N/2}$ при большом $l$.\n",
    "\n",
    "Итак, искомая вероятность не превышает $(1-1/l)^{lN/2} \\rightarrow 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Bagging Implementation</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте беггинг."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from sklearn.base import ClassifierMixin, BaseEstimator\n",
    "from sklearn.utils import resample\n",
    "from scipy.stats import mode\n",
    "from collections import defaultdict\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "\n",
    "class BaggingClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, base_estimator, n_estimators, items_rate=1.0, features_rate=1.0):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        base_estimator: sklearn.Classifier\n",
    "            Базовый алгоритм, который можно обучить (есть метод fit).\n",
    "            Для обучение композиции нужно много таких, можэно получить с помощю copy.deepcopy\n",
    "\n",
    "        n_estimators: int\n",
    "            Число алгоритмов в композиции\n",
    "\n",
    "        items_rate: float > 0\n",
    "            Доля объектов из трейна, на которой будет обучаться каждый базовый алгоритм\n",
    "\n",
    "        features_rate: float > 0\n",
    "            Доля фичей, на которой будет обучаться и применяться каждый базовый алгоритм\n",
    "        \"\"\"\n",
    "        self.n_estimators = n_estimators\n",
    "        self.items_rate = items_rate\n",
    "        self.features_rate = features_rate\n",
    "        self.base_estimator = base_estimator\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Метод должен обучить композицию алгоритмов, используя X, y как обучающую выборку.\n",
    "        Не забудте реализорвать функционал выбора случайных объектов и фичей.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: 2d np.array\n",
    "        y: 1d np.array\n",
    "        \"\"\"\n",
    "        estimators = []\n",
    "        for i in range(self.n_estimators):\n",
    "            estimators.append(deepcopy(self.base_estimator))\n",
    "        self.estimators = estimators\n",
    "        \n",
    "        self.features_idx = []\n",
    "        num_objects = X.shape[0]\n",
    "        num_features = X.shape[1]\n",
    "        num_objects_to_sample = (int)(self.items_rate * num_objects)\n",
    "        num_features_to_sample = (int)(self.features_rate * num_features)\n",
    "        num_objects_to_sample = max(num_objects_to_sample, 1)\n",
    "        num_features_to_sample = max(num_features_to_sample, 1)\n",
    "\n",
    "        for estimator in self.estimators:\n",
    "            X_b, y_b = resample(X, y, n_samples=num_objects_to_sample)\n",
    "            feature_indices, X_b = resample(np.arange(num_features), X_b.T, n_samples=num_features_to_sample, replace=False)\n",
    "            X_b = X_b.T\n",
    "            self.features_idx.append(feature_indices)\n",
    "            estimator.fit(X_b, y_b)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: 2d np.array матрица объекты признаки на которых нужно сказать ответ\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y_pred: 1d np.array, Вектор классов для каждого объекта\n",
    "        \"\"\"\n",
    "        \n",
    "        probs = []\n",
    "        \n",
    "        for est, feats in zip(self.estimators, self.features_idx):\n",
    "            probs.append(est.predict(X.T[feats].T))\n",
    "        probs = np.array(probs)\n",
    "        return mode(probs)[0][0]\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def feature_importances(self):\n",
    "        feat_importances = defaultdict(list)\n",
    "        for estimator, feats in zip(self.estimators, self.features_idx):\n",
    "            for feat, importance in zip(feats, estimator.feature_importances_):\n",
    "                feat_importances[feat].append(importance)\n",
    "        feat_importances = {k: np.mean(np.array(v)) for (k, v) in feat_importances.iteritems()}\n",
    "        return feat_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titanic Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "titanic = pd.read_csv('./data/train.csv')[['Survived', 'Pclass', 'Sex', 'Age', 'Fare']]\n",
    "\n",
    "sex_encoder = LabelEncoder()\n",
    "titanic.Sex = sex_encoder.fit_transform(titanic.Sex)\n",
    "features = ['Pclass', 'Sex', 'Age', 'Fare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 4)\n"
     ]
    }
   ],
   "source": [
    "X, y = titanic[features].values, titanic.Survived.values\n",
    "X = np.nan_to_num(X)\n",
    "X_train, y_train, X_test, y_test = X[:500], y[:500], X[500:], y[500:]\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужно обучить свой беггинг на датасете титаник, и посмотреть работает ли он. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.9 ms, sys: 3.31 ms, total: 14.2 ms\n",
      "Wall time: 11.2 ms\n",
      "0.968 0.795396419437\n"
     ]
    }
   ],
   "source": [
    "# =======================================\n",
    "# Обучите беггинг над DecisionTreeClassifier с 10 моделями\n",
    "# =======================================\n",
    "clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=10)\n",
    "%time clf.fit(X_train, y_train)\n",
    "print accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведите эксперименты:\n",
    "    - Работает-ли беггинг лучше чем просто линейная модель?\n",
    "    - Какой items_rate и features_rate работает лучше и почему?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем сначала второй эксперимент с помощью GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'),\n",
       "         features_rate=0.75, items_rate=0.5, n_estimators=80)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=1)\n",
    "params = {\n",
    "    \"features_rate\": np.linspace(0.25, 1, 4),\n",
    "    \"items_rate\": np.linspace(0.1, 1, 10),\n",
    "    \"n_estimators\": np.arange(10, 150, 10)\n",
    "}\n",
    "gscv = GridSearchCV(clf, params, n_jobs=4, cv=5)\n",
    "gscv.fit(X, y)\n",
    "gscv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82940516273849607"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим лучшие параметры n_estimators=80, items_rate=0.5, features_rate=0.75.\n",
    "\n",
    "Понятно, что items_rate=1.0 и features_rate=1.0 нам не подходят, так как мы хотим маленькую корреляцию между ответами алгоритмов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.92400000000000004, 0.8132992327365729)\n"
     ]
    }
   ],
   "source": [
    "clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=100, features_rate=0.75, items_rate=0.5)\n",
    "clf.fit(X_train, y_train)\n",
    "acc = accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.80000000000000004, 0.76982097186700771)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "acc = accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бэггинг работает лучше, чем линейнеая модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adult Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 108)\n"
     ]
    }
   ],
   "source": [
    "adult = pd.read_csv(\n",
    "    './data/adult.data', \n",
    "    names=[\n",
    "        \"Age\", \"Workclass\", \"fnlwgt\", \"Education\", \"Education-Num\", \"Martial Status\",\n",
    "        \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital Gain\", \"Capital Loss\",\n",
    "        \"Hours per week\", \"Country\", \"Target\"], \n",
    "    header=None, na_values=\"?\")\n",
    "\n",
    "adult = pd.get_dummies(adult)\n",
    "adult[\"Target\"] = adult[\"Target_ >50K\"]\n",
    "X, y = adult[adult.columns[:-3]].values, adult[adult.columns[-1]].values\n",
    "X_train, y_train, X_test, y_test = X[:20000], y[:20000], X[20000:], y[20000:]\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ответте на вопросы:\n",
    "    - Работает-ли беггинг лучше чем просто линейная модель?\n",
    "    - Какой items_rate и features_rate работает лучше и почему?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогично, находим наилучшие параметры с помощью GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'),\n",
      "         features_rate=0.55000000000000004, items_rate=0.55000000000000004,\n",
      "         n_estimators=100)\n",
      "0.864101225392\n"
     ]
    }
   ],
   "source": [
    "clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=1)\n",
    "params = {\n",
    "    \"features_rate\": np.linspace(0.1, 1, 5),\n",
    "    \"items_rate\": np.linspace(0.1, 1, 5),\n",
    "    \"n_estimators\": [30, 60, 100, 120]\n",
    "}\n",
    "gscv = GridSearchCV(clf, params, n_jobs=4, cv=3)\n",
    "gscv.fit(X, y)\n",
    "print(gscv.best_estimator_)\n",
    "print(gscv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим лучшие параметры n_estimators=100, items_rate=0.55, features_rate=0.55.\n",
    "\n",
    "Понятно, что items_rate=1.0 и features_rate=1.0 нам не подходят, так как мы хотим маленькую корреляцию между ответами алгоритмов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.94059999999999999, 0.86147599713398615)\n"
     ]
    }
   ],
   "source": [
    "clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=100, features_rate=0.55, items_rate=0.55)\n",
    "clf.fit(X_train, y_train)\n",
    "acc = accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.80120000000000002, 0.79635379348777968)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "acc = accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что бэггинг работает лучше, чем линейная модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Text, Image Classification</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дальше в каждом эксперименте нужно: \n",
    "- сравниться с линейной моделью ( какую лучше выбрать?=) )\n",
    "- сделать выбор в пользу одной из моделей\n",
    "- выбор обосновать, почему одна из моделей хуже а другая лучше\n",
    "- что такое хуже и лучше\n",
    "- попробуйте беггинг над деревьями и линейными моделями \n",
    "- почему работает или не работает, какие особенности данных на это влияют"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X_train, y_train = vectorizer.fit_transform(newsgroups_train.data), newsgroups_train.target\n",
    "X_test,  y_test  = vectorizer.transform(newsgroups_test.data), newsgroups_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 130107)"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала попробуем RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.996906487538 0.853425385024\n",
      "CPU times: user 13.1 s, sys: 232 ms, total: 13.3 s\n",
      "Wall time: 13.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import RidgeClassifier, LogisticRegression\n",
    "\n",
    "clf = RidgeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.969860350009 0.827934147637\n",
      "CPU times: user 19 s, sys: 446 ms, total: 19.4 s\n",
      "Wall time: 10.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import RidgeClassifier, LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.966855223617 0.824349442379\n",
      "CPU times: user 2.38 s, sys: 64.9 ms, total: 2.44 s\n",
      "Wall time: 1.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "clf = SGDClassifier(loss='log')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшие результаты показывает RidgeClassifier, его и будем использовать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.997260031819 0.7290228359\n",
      "CPU times: user 9min 10s, sys: 7.3 s, total: 9min 17s\n",
      "Wall time: 9min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=100, features_rate=0.5, items_rate=0.5)\n",
    "clf.fit(X_train, y_train)\n",
    "print accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, с данными параметрами BaggingClassifier над DecisionTreeClassifier работает не очень хорошо. Не смотря на то, что у обоих моделей (линейной и бэггинга над деревьями) практически одинаковая ошибка на трейне, ошибка на тесте у BaggingClassifier сильно больше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это объясняется тем, что фичей для BaggingClassifier слишком много. Даже при features_rate=0.5, фичей получается больше 50000, а объектов для тренировки -- всего 10000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также заметим, что процесс занял 10 минут и если мы хотим поподбирать параметры, нам придется уменьшить количество фичей. Оставим 10000 самых часто встречаемых слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=10000)\n",
    "X_train, y_train = vectorizer.fit_transform(newsgroups_train.data), newsgroups_train.target\n",
    "X_test,  y_test  = vectorizer.transform(newsgroups_test.data), newsgroups_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 10000)"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.989923987979 0.824083908656\n",
      "CPU times: user 6.26 s, sys: 100 ms, total: 6.36 s\n",
      "Wall time: 6.74 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = RidgeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "print accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.996818101467 0.732342007435\n",
      "CPU times: user 5min 19s, sys: 8.15 s, total: 5min 27s\n",
      "Wall time: 8min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=100, features_rate=0.5, items_rate=0.5)\n",
    "clf.fit(X_train, y_train)\n",
    "print accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 10000)"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "От того, что мы оставили меньше 10% фичей качетсов линейной модели упало всего на 3%. \n",
    "\n",
    "Интерестные вещи происходят с BaggingClassifier. Качество поднялось на 0.5%. Cкорость обучения увеличилась всего в два раза, в то время как количество фичей упало в 10 раз, время обучения должно было упасть пропорционально. Возможно DecisionTreeClassifier при большом количестве фичей перебирает не все. Также возможно, что большую часть времени заняло выделение и копирования bootstrap подвыборок для базовых алгоритмов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем уменьшить features_rate, а items_rate увеличить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99991161393 0.721720658524\n",
      "CPU times: user 2min 22s, sys: 2.69 s, total: 2min 25s\n",
      "Wall time: 2min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=50, features_rate=0.1, items_rate=1.0)\n",
    "clf.fit(X_train, y_train)\n",
    "print accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качетсво сильно не изменилось, зато время обучения теперь всего 2 минуты! Думаю, что просранство для улучшения BaggingClassifier есть, в частности features_rate=0.1 намекает на то, что n_estimators должен быть большим, хотя бы 1000-2000. Но это уже требует параллельной реализации BaggingClassifier что за рамками этого ДЗ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напоследок попробуем BaggingClassifier над RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.984178893406 0.821030270844\n",
      "CPU times: user 59.7 s, sys: 885 ms, total: 1min\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = BaggingClassifier(RidgeClassifier(), n_estimators=10)\n",
    "clf.fit(X_train, y_train)\n",
    "print accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бэггинг над линейной модели не дал никакого результата, что и логично, ведь у линейных моделей итак низкий разброс."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, вывод: для классификации текста лучше всего подходит линейные модели -- они просты в обучении и быстры, поддерживают онлайн обучение и в рамках предположения Bag of words работают лучше всего"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import load_cifar10\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_cifar10('./data/cifar10')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test = X_train.reshape(X_train.shape[0], -1), X_test.reshape(X_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3072)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала проверим, сбалансированы ли классы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEACAYAAABVtcpZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nf9YVD2G+HX/IAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16bd4dad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала я воспользовался SGDClassifier, но качество на тесте на нем получилось 17%, видимо, гардиентный спуск не обучился. Потом я решил использовать L-BFGS в LogisticRegression в качетсве представителя линейных моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классы сбалансированы, можно продолжать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46048 0.3996\n",
      "CPU times: user 3.15 s, sys: 3.13 s, total: 6.27 s\n",
      "Wall time: 54.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(multi_class='multinomial', class_weight=\"balanced\", solver=\"lbfgs\", n_jobs=4)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что датасет большой. Попробуем сначала обучить хотя бы один DecisionTreeClassifier и замерить время"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72638 0.2501\n",
      "CPU times: user 2min 53s, sys: 9.08 s, total: 3min 2s\n",
      "Wall time: 3min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=1, features_rate=1.0, items_rate=1.0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, обучение занимает 3 минуты. Учитывая, что n_esimators должно быть порядка 100, надо попробовать уменьшить время, отводимое на обучение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72292 0.2459\n",
      "CPU times: user 10.2 s, sys: 7.21 s, total: 17.4 s\n",
      "Wall time: 20.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = BaggingClassifier(DecisionTreeClassifier(max_features=\"sqrt\"), n_estimators=1, features_rate=1.0, items_rate=1.0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уже лучше. Теперь запустим обучение на 10 базовых алгоритмах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99316 0.3621\n",
      "CPU times: user 1min 44s, sys: 59.4 s, total: 2min 43s\n",
      "Wall time: 3min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = BaggingClassifier(DecisionTreeClassifier(max_features=\"sqrt\"), n_estimators=10, features_rate=1.0, items_rate=1.0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем версию из sklearn, она же параллельная."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier as BaggingClassifier_sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9938 0.358\n",
      "CPU times: user 19.6 s, sys: 8.61 s, total: 28.2 s\n",
      "Wall time: 5min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = BaggingClassifier_sklearn(DecisionTreeClassifier(max_features=\"sqrt\"), n_estimators=10, n_jobs=4)\n",
    "clf.fit(X_train, y_train)\n",
    "print accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Странно, получилось медленнее (по wall time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустим на 30 базовых алгоритмах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99992 0.4229\n",
      "CPU times: user 5min, sys: 2min 2s, total: 7min 3s\n",
      "Wall time: 7min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = BaggingClassifier(DecisionTreeClassifier(max_features=\"sqrt\"), n_estimators=30, features_rate=1.0, items_rate=1.0)\n",
    "clf.fit(X_train, y_train)\n",
    "print accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы смогли обогнать линейную модель на тесте. \n",
    "\n",
    "Время почему-то увеличивается не пропорционально количеству деревьев. Попробуем 50 базовых алгоритмов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.4507\n",
      "CPU times: user 8min 27s, sys: 3min 25s, total: 11min 52s\n",
      "Wall time: 13min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = BaggingClassifier(DecisionTreeClassifier(max_features=\"sqrt\"), n_estimators=50, features_rate=1.0, items_rate=1.0)\n",
    "clf.fit(X_train, y_train)\n",
    "print accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, мы смогли улучшить результат линейной модели на 5% с помощью бэггинга над решающими деревьями. По сравнению с предидущей задачей, здесь гораздо меньше фичей, следовательно, нужно сильно меньше базовых алгоритмов, чтобы хоть как-то уменьшить разброс, а именно уменьшение разброса делает бэггинг таким эффективным"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Random Forest Feature Impotance</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Опишите как вычисляется важность фичей в дереве, можите изучить как работает  feature\\_importances_ в sklearn.\n",
    "\n",
    "---\n",
    "\n",
    "Для данного признака считается нормализованное уменьшение критреия джини, вызванное всеми вершинами, в которой происходило разбиение по этому признаку "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Почитайте Feature Impotance для Adult и Titanic (используйте полный датасет), ПРОИНТЕРПРЕТИРУЙТЕ резульататы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = adult[adult.columns[:-3]].values, adult[adult.columns[-1]].values\n",
    "X_train, y_train, X_test, y_test = X[:20000], y[:20000], X[20000:], y[20000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=100, \n",
    "                        items_rate=1, features_rate=1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.11378498603517966,\n",
       " 1: 0.16762776936826299,\n",
       " 2: 0.11044508979167243,\n",
       " 3: 0.10356352821759308,\n",
       " 4: 0.038649427363131018,\n",
       " 5: 0.064629658109361235,\n",
       " 6: 0.001568665206948349,\n",
       " 7: 0.0052798590513474805,\n",
       " 8: 0.0062047888287784583,\n",
       " 9: 0.0,\n",
       " 10: 0.0098733896499170141,\n",
       " 11: 0.0065685270210114584,\n",
       " 12: 0.0092348569031112989,\n",
       " 13: 0.0043567023701978338,\n",
       " 14: 0.0,\n",
       " 15: 0.00068313296087743136,\n",
       " 16: 0.000613657969579491,\n",
       " 17: 0.0004701312134365159,\n",
       " 18: 0.00010088421629927685,\n",
       " 19: 0.00014267735430785274,\n",
       " 20: 0.00048472157594416017,\n",
       " 21: 0.00047029838904998728,\n",
       " 22: 0.001350822642194651,\n",
       " 23: 0.0026028699925275504,\n",
       " 24: 0.0026649890696578936,\n",
       " 25: 0.00071548227056130462,\n",
       " 26: 0.0033497140952469455,\n",
       " 27: 0.002675876894981576,\n",
       " 28: 0.00010150812051733752,\n",
       " 29: 0.0013057681690004464,\n",
       " 30: 0.0040831102782392659,\n",
       " 31: 0.0021306073921483811,\n",
       " 32: 0.00040772721821852336,\n",
       " 33: 0.19590384945851508,\n",
       " 34: 0.00064980530000458903,\n",
       " 35: 0.0018445752079852067,\n",
       " 36: 0.001122566906624322,\n",
       " 37: 0.001115083743570913,\n",
       " 38: 0.0015429406185034399,\n",
       " 39: 0.006124313874029186,\n",
       " 40: 9.1395270511711188e-06,\n",
       " 41: 0.0083719231127033049,\n",
       " 42: 0.011860126432538427,\n",
       " 43: 0.0036642744350634826,\n",
       " 44: 0.0030440220472912967,\n",
       " 45: 0.0052112983905481143,\n",
       " 46: 0.004568286575675564,\n",
       " 47: 1.3381571099506625e-05,\n",
       " 48: 0.0094091723168170192,\n",
       " 49: 0.0033755850748188377,\n",
       " 50: 0.008193060623631461,\n",
       " 51: 0.0056641958454685939,\n",
       " 52: 0.0056461242112174868,\n",
       " 53: 0.0023976818444791481,\n",
       " 54: 0.0022480372886667672,\n",
       " 55: 0.0012764817989611194,\n",
       " 56: 0.0014898119086543191,\n",
       " 57: 0.001425662061652137,\n",
       " 58: 0.0039017848387073138,\n",
       " 59: 0.00097112862702532058,\n",
       " 60: 0.0019860964654618523,\n",
       " 61: 0.0039759037321191399,\n",
       " 62: 0.0006384617152875989,\n",
       " 63: 0.0052718682203441534,\n",
       " 64: 0.0044375074127923856,\n",
       " 65: 0.0042416669285103509,\n",
       " 66: 0.0023104152600713652,\n",
       " 67: 0.00026538180121525557,\n",
       " 68: 0.0011213531655709416,\n",
       " 69: 0.00031543473321525524,\n",
       " 70: 3.4336725037893355e-05,\n",
       " 71: 0.00069839979155003065,\n",
       " 72: 9.0343627020805908e-05,\n",
       " 73: 7.2496940888637691e-05,\n",
       " 74: 4.1586832262251681e-05,\n",
       " 75: 0.0009512159582024945,\n",
       " 76: 0.00017938916684622161,\n",
       " 77: 0.0011527222991965954,\n",
       " 78: 0.00022965074139647663,\n",
       " 79: 1.8897250622377685e-05,\n",
       " 80: 1.7831704032041259e-05,\n",
       " 81: 0.0,\n",
       " 82: 0.0,\n",
       " 83: 0.00014668920476566992,\n",
       " 84: 0.00019854929713572074,\n",
       " 85: 0.00094836583938711901,\n",
       " 86: 0.00054963712711501064,\n",
       " 87: 0.00023267852396295741,\n",
       " 88: 0.00097593063396802387,\n",
       " 89: 0.00060188374019779032,\n",
       " 90: 0.00066937492281228918,\n",
       " 91: 3.2215978666185525e-06,\n",
       " 92: 0.0010731694955917748,\n",
       " 93: 2.9696365420863363e-05,\n",
       " 94: 1.0685171920569003e-05,\n",
       " 95: 2.0813452150393846e-06,\n",
       " 96: 0.00086041980457235445,\n",
       " 97: 0.00068528081909733003,\n",
       " 98: 0.00034159055919357915,\n",
       " 99: 0.00040167492523913778,\n",
       " 100: 5.6269632732956947e-06,\n",
       " 101: 0.00062505280503791271,\n",
       " 102: 0.00023054580526908372,\n",
       " 103: 2.9496090961949514e-05,\n",
       " 104: 1.2583411006313484e-05,\n",
       " 105: 0.0053195135099468127,\n",
       " 106: 0.00021883940325604986,\n",
       " 107: 0.00059091078553871431}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самыми важными оказались 1 и 33 фича. Попробуем получить список фичей с feature_importance > 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "important_keys = [k for (k, v) in clf.feature_importances.iteritems() if v > 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Age', u'fnlwgt', u'Education-Num', u'Capital Gain',\n",
       "       u'Martial Status_ Married-civ-spouse'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult.columns[important_keys]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В числе важных признаков -- образование, возраст, прирост капитала, семейное положение, что вполне логично"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = titanic[features].values, titanic.Survived.values\n",
    "X = np.nan_to_num(X)\n",
    "X_train, y_train, X_test, y_test = X[:500], y[:500], X[500:], y[500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=100, \n",
    "                        items_rate=1, features_rate=1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.082254086833973103,\n",
       " 1: 0.33836958715051202,\n",
       " 2: 0.24692036365376172,\n",
       " 3: 0.33245596236175301}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, самыми важными оказались фичи Sex и Fare. Видимо, мужчины выживали чаще, а от fare зависил денежный статус"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
